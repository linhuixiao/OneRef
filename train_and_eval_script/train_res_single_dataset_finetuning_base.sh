export CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7
echo "train_rec_single_dataset_finetuning_base.sh"
# 测试时间 20220831

# Due to the limited number of data samples in the single-dataset setting, MRefM did not yield significant improvements in performance. To streamline the training process and facilitate the reproducibility of our work, we provide a training approach without MRefM pre-training specifically for the single-dataset scenario.

######## warmup
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset unc       --use_mask_loss  --enable_seg_mask  --frozen_backbone           --finetune /patch_to/beit3_checkpoint/beit3_base_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v001/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset unc+      --use_mask_loss  --enable_seg_mask  --frozen_backbone           --finetune /patch_to/beit3_checkpoint/beit3_base_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v001/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset gref_umd  --use_mask_loss  --enable_seg_mask  --frozen_backbone           --finetune /patch_to/beit3_checkpoint/beit3_base_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v001/unc+;

## finetuning training
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 24 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset unc       --use_mask_loss  --enable_seg_mask                              --finetune /path_to/oneref/output/RES/v001/unc/best_checkpoint.pth            --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 24 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset unc+      --use_mask_loss  --enable_seg_mask                              --finetune /path_to/oneref/output/RES/v001/unc+/best_checkpoint.pth           --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 24 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset gref_umd  --use_mask_loss  --enable_seg_mask                              --finetune /path_to/oneref/output/RES/v001/gref_umd/best_checkpoint.pth       --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v002/gref_umd;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 32 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset referit   --use_mask_loss  --enable_seg_mask                              --finetune /path_to/oneref/output/RES/v001/referit/best_checkpoint.pth        --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v002/referit;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 32 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset flickr    --use_mask_loss  --enable_seg_mask                              --finetune /path_to/oneref/output/RES/v001/flickr/best_checkpoint.pth         --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/RES/v002/flickr;


# eval :
# RefCOCO unc
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset unc      --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/unc/best_checkpoint.pth      --output_dir /path_to/oneref/output/RES/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset unc      --eval_set testA --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/unc/best_checkpoint.pth      --output_dir /path_to/oneref/output/RES/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset unc      --eval_set testB --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/unc/best_checkpoint.pth      --output_dir /path_to/oneref/output/RES/v002/unc;
## RefCOCO+ unc+
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset unc+     --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/unc+/best_checkpoint.pth     --output_dir /path_to/oneref/output/RES/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset unc+     --eval_set testA --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/unc+/best_checkpoint.pth     --output_dir /path_to/oneref/output/RES/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset unc+     --eval_set testB --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/unc+/best_checkpoint.pth     --output_dir /path_to/oneref/output/RES/v002/unc+;
## gref_umd
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset gref_umd --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/gref_umd/best_checkpoint.pth --output_dir /path_to/oneref/output/RES/v002/gref_umd;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --use_mask_loss --enable_seg_mask --dataset gref_umd --eval_set test  --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/RES/v002/gref_umd/best_checkpoint.pth --output_dir /path_to/oneref/output/RES/v002/gref_umd;
