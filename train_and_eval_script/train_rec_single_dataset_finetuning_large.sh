export CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7
echo "train_rec_single_dataset_finetuning_large.sh"
# 测试时间 20220831
# Due to the limited number of data samples in the single-dataset setting, MRefM did not yield significant improvements in performance. To streamline the training process and facilitate the reproducibility of our work, we provide a training approach without MRefM pre-training specifically for the single-dataset scenario.

######## warmup
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset unc      --use_regress_box  --frozen_backbone                                 --finetune /patch_to/beit3_checkpoint/beit3_large_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v001/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset unc+     --use_regress_box  --frozen_backbone                                 --finetune /patch_to/beit3_checkpoint/beit3_large_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v001/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset gref_umd --use_regress_box  --frozen_backbone                                 --finetune /patch_to/beit3_checkpoint/beit3_large_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v001/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset referit  --use_regress_box  --frozen_backbone                                 --finetune /patch_to/beit3_checkpoint/beit3_large_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v001/referit;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10 --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset flickr   --use_regress_box  --frozen_backbone                                 --finetune /patch_to/beit3_checkpoint/beit3_large_indomain_patch16_224.pth --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v001/flickr;


## finetuning training
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 8 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset unc      --use_regress_box   --use_box_mask_constraints                        --finetune /path_to/oneref/output/v001/unc/best_checkpoint.pth         --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 8 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset unc+     --use_regress_box   --use_box_mask_constraints                        --finetune /path_to/oneref/output/v001/unc+/best_checkpoint.pth        --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 8 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset gref_umd --use_regress_box   --use_box_mask_constraints                        --finetune /path_to/oneref/output/v001/gref_umd/best_checkpoint.pth    --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v002/gref_umd;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 8 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset referit  --use_regress_box   --use_box_mask_constraints                        --finetune /path_to/oneref/output/v001/referit/best_checkpoint.pth     --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v002/referit;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20 --batch_size 8 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_large_patch16_384 --task grounding  --dataset flickr   --use_regress_box   --use_box_mask_constraints                        --finetune /path_to/oneref/output/v001/flickr/best_checkpoint.pth      --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --output_dir /path_to/oneref/output/v002/flickr;


# eval :
# RefCOCO unc
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset unc      --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/unc/best_checkpoint.pth      --output_dir /path_to/oneref/output/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset unc      --eval_set testA --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/unc/best_checkpoint.pth      --output_dir /path_to/oneref/output/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset unc      --eval_set testB --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/unc/best_checkpoint.pth      --output_dir /path_to/oneref/output/v002/unc;
## RefCOCO+ unc+
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset unc+     --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/unc+/best_checkpoint.pth     --output_dir /path_to/oneref/output/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset unc+     --eval_set testA --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/unc+/best_checkpoint.pth     --output_dir /path_to/oneref/output/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset unc+     --eval_set testB --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/unc+/best_checkpoint.pth     --output_dir /path_to/oneref/output/v002/unc+;
## gref_umd
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset gref_umd --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/gref_umd/best_checkpoint.pth --output_dir /path_to/oneref/output/v002/gref_umd;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset gref_umd --eval_set test  --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/gref_umd/best_checkpoint.pth --output_dir /path_to/oneref/output/v002/gref_umd;
## ReferItGame
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset referit  --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/referit/best_checkpoint.pth  --output_dir /path_to/oneref/output/v002/referit;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset referit  --eval_set test  --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/referit/best_checkpoint.pth  --output_dir /path_to/oneref/output/v002/referit;
## flickr
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset flickr   --eval_set val   --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/flickr/best_checkpoint.pth   --output_dir /path_to/oneref/output/v002/flickr;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --imsize 384 --max_query_len 64 --model beit3_large_patch16_384 --task grounding --dataset flickr   --eval_set test  --data_root /patch_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset  --eval_model /path_to/oneref/output/v002/flickr/best_checkpoint.pth   --output_dir /path_to/oneref/output/v002/flickr;


