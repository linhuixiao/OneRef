# finetuning  for RefCOCO/RefCOCO+/RefCOCOg
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10  --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset mixup   --use_regress_box  --frozen_backbone                            --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --finetune /path_to/outputs/oneref/pretrain/checkpoint.pth             --data_root /path_to_image_data --split_root /path_to/annotation/refer_LAVT/ref_data_shuffled/mixup_with_refc    --output_dir /path_to/outputs/oneref/v001/mixup;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20  --batch_size 32 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset mixup   --use_regress_box  --use_box_mask_constraints                   --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --finetune /path_to/outputs/oneref/v001/mixup/best_checkpoint.pth      --data_root /path_to_image_data --split_root /path_to/annotation/refer_LAVT/ref_data_shuffled/mixup_with_refc    --output_dir /path_to/outputs/oneref/v002/mixup;

# finetuning  for ReferIt
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10  --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset referit --use_regress_box  --frozen_backbone                            --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --finetune /path_to/outputs/oneref/pretrain/checkpoint.pth             --data_root /path_to_image_data --split_root /path_to/annotation/refer_LAVT/ref_data_shuffled/single_dataset --output_dir /path_to/outputs/oneref/v001/referit;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20  --batch_size 32 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset referit --use_regress_box  --use_box_mask_constraints                   --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --finetune /path_to/outputs/oneref/v001/referit/best_checkpoint.pth    --data_root /path_to_image_data --split_root /path_to/annotation/refer_LAVT/ref_data_shuffled/single_dataset --output_dir /path_to/outputs/oneref/v002/referit;

# finetuning  for Flickr
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 10  --batch_size 64 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset flickr  --use_regress_box  --frozen_backbone                            --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --finetune /path_to/outputs/oneref/pretrain/checkpoint.pth             --data_root /path_to_image_data --split_root /path_to/annotation/refer_LAVT/ref_data_shuffled/single_dataset --output_dir /path_to/outputs/oneref/v001/flickr;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28887 --use_env train_oneref.py --num_workers 4 --epochs 20  --batch_size 32 --lr 0.00003  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate    --imsize 384 --max_query_len 64  --model beit3_base_patch16_384 --task grounding  --dataset flickr  --use_regress_box  --use_box_mask_constraints                   --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --finetune /path_to/outputs/oneref/v001/flickr/best_checkpoint.pth     --data_root /path_to_image_data --split_root /path_to/annotation/refer_LAVT/ref_data_shuffled/single_dataset --output_dir /path_to/outputs/oneref/v002/flickr;


#### test
#
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset unc      --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to/outputs/oneref/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset unc      --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set testA  --output_dir /path_to/outputs/oneref/v002/unc;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset unc      --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set testB  --output_dir /path_to/outputs/oneref/v002/unc;
#
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset unc+     --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to/outputs/oneref/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset unc+     --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set testA  --output_dir /path_to/outputs/oneref/v002/unc+;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset unc+     --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set testB  --output_dir /path_to/outputs/oneref/v002/unc+;
#
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset gref_umd --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to/outputs/oneref/v002/gref_umd;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset gref_umd --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/mixup/best_checkpoint.pth --eval_set test   --output_dir /path_to/outputs/oneref/v002/gref_umd;
#
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset referit  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/referit/best_checkpoint.pth --eval_set val  --output_dir /path_to/outputs/oneref/v002/referit;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset referit  --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/referit/best_checkpoint.pth --eval_set test --output_dir /path_to/outputs/oneref/v002/referit;
#
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset flickr   --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/flickr/best_checkpoint.pth --eval_set val   --output_dir /path_to/outputs/oneref/v002/flickr;
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=8 --master_port 28888 --use_env eval.py --num_workers 4 --batch_size 128  --dataset flickr   --imsize 384 --max_query_len 64 --model beit3_base_patch16_384 --task grounding --data_root /path_to_image_data --split_root /path_to/ref_data_shuffled/single_dataset --sentencepiece_model /path_to/checkpoint/beit3/beit3.spm --eval_model /path_to/outputs/oneref/v002/flickr/best_checkpoint.pth --eval_set test  --output_dir /path_to/outputs/oneref/v002/flickr;
#

